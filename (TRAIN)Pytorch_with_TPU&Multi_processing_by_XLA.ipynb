{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(TRAIN)Pytorch with TPU&Multi-processing  by XLA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOnIgbxSza8GK0QH0Pnyg8J"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8cSXRXPUn4e"
      },
      "source": [
        "#Insert TPU activity into https://www.kaggle.com/yasufuminakama/ranzcr-resnext50-32x4d-starter-training\n",
        "#Refered to TPU implementation https://www.kaggle.com/dimitreoliveira/cassava-leaf-disease-tpu-tensorflow-training\n",
        "#Refered to XLA documentation(and code) https://pytorch.org/xla/release/1.8/index.html \n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3YmLdr3w1iF"
      },
      "source": [
        "#RepositoryName"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBz_gjFgw8Oe"
      },
      "source": [
        "FLAGS = {}\n",
        "FLAGS['COMP_NAME'] = 'plant-pathology-2021-fgvc8'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdUfZfEuVM2P"
      },
      "source": [
        "#Hardware settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWgKr_YsVW4Z"
      },
      "source": [
        "##Colab Only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhrxEDLEVUmw",
        "outputId": "dee7646f-ed3f-4e4a-a848-1e49a7fe3b8e"
      },
      "source": [
        "#Check TPU status\n",
        "import os\n",
        "from tensorflow.python.profiler import profiler_client\n",
        "\n",
        "tpu_profile_service_address = os.environ['COLAB_TPU_ADDR'].replace('8470', '8466')\n",
        "print(profiler_client.monitor(tpu_profile_service_address, 100, 2))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Timestamp: 10:29:44\n",
            "  TPU type: TPU v2\n",
            "  Utilization of TPU Matrix Units (higher is better): 0.000%\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hn04dFMUXMf",
        "outputId": "0729ba58-237d-4de5-ffcd-6a3392b5be32"
      },
      "source": [
        "#Check GPU status\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, \n",
            "and then re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBF97WJIVLf6",
        "outputId": "716eee0e-d728-4e71-872f-3e2fcf7ea65b"
      },
      "source": [
        "#Check Memory size\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 38.0 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "EPq24E54YLyC",
        "outputId": "fd7b5030-a190-4932-d245-ab0c4c5910b9"
      },
      "source": [
        "#Connect Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "! mkdir -p ~/.kaggle\n",
        "! cp \"drive/My Drive/kaggle/kaggle.json\" ~/.kaggle/\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "! kaggle config view\n",
        "ROOT_DIR=\"/content/drive/MyDrive\"\n",
        "INPUT_DIR=\"/kaggle/input\"\n",
        "FLAGS['MODEL_PATH'] = f\"{ROOT_DIR}/kaggle/output/{FLAGS['COMP_NAME']}/pth/\"\n",
        "\n",
        "%cd $ROOT_DIR$INPUT_DIR"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d980cdc08aaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Connect Google drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' mkdir -p ~/.kaggle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' cp \"drive/My Drive/kaggle/kaggle.json\" ~/.kaggle/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    258\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs-auth-dance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m           \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8s3oP5_8YWU0"
      },
      "source": [
        "##TPU setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-lmGl7IYPCq"
      },
      "source": [
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8-cp37-cp37m-linux_x86_64.whl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJCeIb70tMm1"
      },
      "source": [
        "#Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXp4pC3EZVC4"
      },
      "source": [
        "!pip install timm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3dzFl0Dn1Nj"
      },
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps albumentations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzUyYi_8tKln"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import timm\n",
        "\n",
        "from albumentations import (\n",
        "    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n",
        "    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n",
        "    IAAAdditiveGaussianNoise, Transpose\n",
        "    )\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import math\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3sUs8nRz9e0"
      },
      "source": [
        "def seed_torch(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_torch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WA4_JwQmbOLD"
      },
      "source": [
        "#Parameters(Non-tuning)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6Wc1_ZyYXiI"
      },
      "source": [
        "#data\n",
        "FLAGS['OS_LIST_DIR'] = f\"../input/{FLAGS['COMP_NAME']}\"\n",
        "FLAGS['TRAIN_PATH'] = f\"{FLAGS['OS_LIST_DIR']}/train_images\"\n",
        "FLAGS['image_size'] = 384\n",
        "#model\n",
        "FLAGS['model_name'] = 'resnext50_32x4d'\n",
        "FLAGS['target_size'] = 12\n",
        "#output\n",
        "FLAGS['OUTPUT_DIR'] = f\"{ROOT_DIR}/kaggle/output/{FLAGS['COMP_NAME']}/pth/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhW1EqrYtaQz"
      },
      "source": [
        "#LoadData"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGtJvJb7lJdL"
      },
      "source": [
        "os.listdir(FLAGS['OS_LIST_DIR'] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALlOZqfSbZt3"
      },
      "source": [
        "database_base_path = '../input/plant-pathology-2021-fgvc8/'\n",
        "train = pd.read_csv(f'{database_base_path}train.csv')\n",
        "print(f'Train samples: {len(train)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdxrIoxU5tYW"
      },
      "source": [
        "train.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiT7QBoSuHtz"
      },
      "source": [
        "#EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPFmhltbuIks"
      },
      "source": [
        "train.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLCJiSWVLDRE"
      },
      "source": [
        "display(train.groupby('labels', as_index=False).count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9y-LVn2hAWm"
      },
      "source": [
        "labels = list(train['labels'].value_counts().keys())\n",
        "labels_dict = dict(zip(labels, range(12)))\n",
        "train['labels'] = train['labels'].replace(labels_dict)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsswRq7tuJDD"
      },
      "source": [
        "#Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D7XCs38uKE8"
      },
      "source": [
        "#Update later"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FNz_yjduK2N"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOOsrq7YuNzb"
      },
      "source": [
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, model_name=FLAGS['model_name'], pretrained=True):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(model_name, pretrained)\n",
        "        n_features = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(n_features, FLAGS['target_size'])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRBwE3te2CCk"
      },
      "source": [
        "SERIAL_EXEC = xmp.MpSerialExecutor()\n",
        "WRAPPED_MODEL = xmp.MpModelWrapper(CustomModel())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7qbSHo3Y1AM"
      },
      "source": [
        "#Util"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zokwJ0CeY0nZ"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%02dm %02ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (Remain %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDjbJCM_uOyh"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDEcd4Pph90d"
      },
      "source": [
        "##Transforming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LM9PI2fqpc2M"
      },
      "source": [
        "def get_transforms(*, data): \n",
        "        return Compose([\n",
        "            RandomResizedCrop(FLAGS['image_size'], FLAGS['image_size'], scale=(0.85, 1.0)),\n",
        "            HorizontalFlip(p=0.5),\n",
        "            Normalize(\n",
        "                mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225],\n",
        "            ),\n",
        "            ToTensorV2(),\n",
        "        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO8difsLFFn1"
      },
      "source": [
        "class TrainDataset(Dataset):\n",
        "  def __init__(self, df, transform=None):\n",
        "    self.df = df\n",
        "    self.file_names = df['image'].values\n",
        "    self.labels = df['labels'].values\n",
        "    self.transform = transform\n",
        "        \n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    file_name = self.file_names[idx]\n",
        "    file_path = f\"{FLAGS['TRAIN_PATH']}/{file_name}\"\n",
        "    image = cv2.imread(file_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    if self.transform:\n",
        "      augmented = self.transform(image=image)\n",
        "      image = augmented['image']\n",
        "      label = torch.tensor(self.labels[idx]).float()\n",
        "    return image, label\n",
        "\n",
        "  def __call__(self):\n",
        "    print('callable is called')\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNXAZKVDGNyW"
      },
      "source": [
        "train_dataset = TrainDataset(train, transform=get_transforms(data='train'))\n",
        "\n",
        "for i in range(5):\n",
        "    image, label = train_dataset[i]\n",
        "    plt.imshow(image[0])\n",
        "    plt.title(f'label: {label}')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlFbY4fqiA7p"
      },
      "source": [
        "##Training func"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSvsuf2ieJqI"
      },
      "source": [
        "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
        "  model.train()\n",
        "\n",
        "  data_time = AverageMeter()\n",
        "  losses = AverageMeter()\n",
        "\n",
        "  start = end = time.time()\n",
        "\n",
        "  para_loader = pl.ParallelLoader(train_loader, [device])\n",
        "\n",
        "  for step, (images, labels) in enumerate(para_loader.per_device_loader(device)):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    data_time.update(time.time() - end)\n",
        "    \n",
        "    batch_size = labels.size(0)\n",
        "\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    y_preds = model(images)\n",
        "    loss = criterion(y_preds, labels)\n",
        "    losses.update(loss.item(), batch_size)\n",
        "\n",
        "    loss.backward()\n",
        "    xm.optimizer_step(optimizer, barrier=False)\n",
        "\n",
        "    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), FLAGS['max_grad_norm'])\n",
        "    \n",
        "    end = time.time()\n",
        "\n",
        "    if step % FLAGS['print_freq'] == 0 or step == (len(train_loader)-1):\n",
        "      xm.master_print('TRIN:[{epoch:02}][{step:03}/{total}] '\n",
        "                  'Time:{time}　'\n",
        " #                 'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
        "                  'Elapsed {remain:s} '\n",
        "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
        "                  'Grad: {grad_norm:.4f}  '\n",
        "                  #'LR: {lr:.6f}  '\n",
        "                  .format(\n",
        "                   epoch=epoch+1, step=step+1, total=len(train_loader),\n",
        "                   data_time=data_time, loss=losses,\n",
        "                   remain=timeSince(start, float(step+1)/len(train_loader)),\n",
        "                   grad_norm=grad_norm,\n",
        "                   #lr=scheduler.get_lr()[0],\n",
        "                   time=datetime.datetime.fromtimestamp(end).strftime('%b %d, %Y %I:%M:%S%p')\n",
        "                   ))\n",
        "      #xm.master_print(profiler_client.monitor(tpu_profile_service_address, 100, 2))\n",
        "\n",
        "  return losses.avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3fBH6BOuTKy"
      },
      "source": [
        "def train_loop():\n",
        "  \n",
        "  serialized_train_dataset = train_dataset\n",
        "\n",
        "  train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "      serialized_train_dataset,\n",
        "      num_replicas=xm.xrt_world_size(),\n",
        "      rank=xm.get_ordinal(),\n",
        "      shuffle=True)\n",
        "  \n",
        "  train_loader = DataLoader(serialized_train_dataset,\n",
        "                            batch_size=FLAGS['batch_size'],\n",
        "                            sampler=train_sampler,\n",
        "                            num_workers=FLAGS['num_workers'],\n",
        "                            drop_last=True)\n",
        " \n",
        "  device = xm.xla_device()\n",
        "\n",
        "  model = WRAPPED_MODEL.to(device)\n",
        "\n",
        "  optimizer = Adam(model.parameters(), lr=FLAGS['learning_rate'] , weight_decay=FLAGS['weight_decay'], amsgrad=False)\n",
        "\n",
        "  scheduler = CosineAnnealingLR(optimizer, T_max=FLAGS['T_max'], eta_min=FLAGS['min_lr'], last_epoch=-1)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  for epoch in range(FLAGS['num_epochs']):\n",
        "\n",
        "    train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
        "\n",
        "  xm.save(model.state_dict(), f\"{FLAGS['MODEL_PATH']}{FLAGS['model_name']}.pth\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACl-hvn_uiWi"
      },
      "source": [
        "#Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFdyg-RvujLn"
      },
      "source": [
        "def _mp_fn(index, flags):\n",
        "  train_loop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AR8k-8MSYIn"
      },
      "source": [
        "#Parameters(Tuning)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n47pur9-SXas"
      },
      "source": [
        "#training\n",
        "FLAGS['batch_size'] = 8\n",
        "FLAGS['num_workers'] = 2\n",
        "FLAGS['learning_rate'] = 2e-4\n",
        "FLAGS['min_lr'] = 2e-5\n",
        "FLAGS['T_max'] = 6e5\n",
        "FLAGS['weight_decay'] = 1e-4\n",
        "FLAGS['num_cores'] = 8\n",
        "FLAGS['num_epochs'] = 1\n",
        "FLAGS['print_freq'] = 100\n",
        "FLAGS['max_grad_norm']=1e3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPr9GxuJuUcN"
      },
      "source": [
        "#Execute Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKMvrX87uVAK"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "  #best_loss = Value('d', np.inf)\n",
        "\n",
        "  xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=FLAGS['num_cores'], start_method='fork')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRmUlo0tY4kx"
      },
      "source": [
        "#(Colab Only)Wrap up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NIiJShsziK3"
      },
      "source": [
        "##Upload models to Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxzwWunQzgB8"
      },
      "source": [
        "OUTPUT_DIR=FLAGS['OUTPUT_DIR']\n",
        "%cd $OUTPUT_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7ikLowuQpDj"
      },
      "source": [
        "#!kaggle datasets init -p ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53kPk8P6XeVu"
      },
      "source": [
        "ls -la"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRsiyt3Bx3JL"
      },
      "source": [
        "!kaggle datasets create"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d9iv62IXhog"
      },
      "source": [
        "!kaggle datasets version -m versionup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW9h7mii1FDr"
      },
      "source": [
        "##OOM memo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-bI3VOJLZgc"
      },
      "source": [
        "#image_size=600, batch_size=16\n",
        "#(0) Resource exhausted: Ran out of memory in memory space hbm. Used 8.27G of 7.98G\n",
        "#16*600*x=8270M   x=0.86\n",
        "\n",
        "#image size (y) when batch size16\n",
        "#16*y*0.86<8000M    y<581   したがって８の倍数の576。"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75M_8l_23fpq"
      },
      "source": [
        "#image_size=576, batch_size=16\n",
        "#(0) Resource exhausted: Ran out of memory in memory space hbm. Used 8.04G of 7.98G hbm. Exceeded hbm capacity by 64.82M.\n",
        "#16*576*576*x=8,270,000   x=1.557"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ4OKreM1UI1"
      },
      "source": [
        "#Re-calc by square\n",
        "#image_size=600, batch_size=16\n",
        "#(0) Resource exhausted: Ran out of memory in memory space hbm. Used 8.27G of 7.98G\n",
        "#16*600*600*x=8,270,000K  x=1.435\n",
        "\n",
        "#image size (y) when batch size16\n",
        "#16*y*y*1.435<8,000,000    y<590?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VniucG_G49o4"
      },
      "source": [
        "#image_size=560, batch_size=16\n",
        "# (0) Resource exhausted: Ran out of memory in memory space hbm. Used 8.01G of 7.98G hbm. Exceeded hbm capacity by 25.74M."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtXRVhi-5yyH"
      },
      "source": [
        "#image_size=552, batch_size=16\n",
        "#  (0) Resource exhausted: Ran out of memory in memory space hbm. Used 8.08G of 7.98G hbm. Exceeded hbm capacity by 100.82M.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuraREP-7qrX"
      },
      "source": [
        "#image_size=520, batch_size=16\n",
        "#  (0) Resource exhausted: Failed to allocate request for 60.94MiB "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHQtQu6W_zc8"
      },
      "source": [
        "#image_size=496, batch_size=16\n",
        "#  (1) Resource exhausted: Failed to allocate request for 46.50MiB (48758784B) on device ordinal 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CUzk_KGDoFm"
      },
      "source": [
        "#image_size=496, batch_size=16\n",
        "#  (0) Resource exhausted: Failed to allocate request for 45.00MiB (47185920B) on device ordinal 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fohl07Xx5Gw"
      },
      "source": [
        "#image_size=600, batch_size=8\n",
        "#Success!"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}